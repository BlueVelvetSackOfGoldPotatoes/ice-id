{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae3101b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Data Preprocessing ---\n",
      "Loading people.csv...\n",
      "Canonicalizing names and flags...\n",
      "Loading manntol_einstaklingar_new.csv and merging ID columns…\n",
      "Merging geography data via manntol IDs…\n",
      "Imputing static attributes…\n",
      "Including ALL rows for ML features and graph…\n",
      "→ 984028 total rows\n",
      "Defining feature sets…\n",
      "Creating numeric features…\n",
      "One-hot encoding low-cardinality…\n",
      "Ordinal encoding high-cardinality…\n",
      "Saving sparse features...\n",
      "Creating temporal graph…\n",
      "Graph: 984028 nodes, 266817 undirected edges.\n",
      "--- Data Preprocessing Finished ---\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from pathlib import Path\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Configuration\n",
    "# ---------------------------------------------------------------------------\n",
    "DATA_DIR   = Path(\"raw_data\")  # Input CSVs directory\n",
    "ART_DIR    = Path(\"artifacts\") # Output artifacts directory\n",
    "ART_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"--- Starting Data Preprocessing ---\")\n",
    "\n",
    "# 1) Load & lowercase\n",
    "print(\"Loading people.csv...\")\n",
    "people = pd.read_csv(\n",
    "    DATA_DIR / \"people.csv\",\n",
    "    low_memory=False,\n",
    "    dtype={\"first_name\": str, \"middle_name\": str, \"patronym\": str, \"surname\": str}\n",
    ")\n",
    "people.columns = people.columns.str.lower().str.strip()\n",
    "people = people.set_index(\"id\")\n",
    "\n",
    "# 2) Canonicalize names & flags\n",
    "print(\"Canonicalizing names and flags...\")\n",
    "NAME_COLS = [\"first_name\", \"middle_name\", \"patronym\", \"surname\"]\n",
    "for col in NAME_COLS:\n",
    "    if col not in people.columns:\n",
    "        people[col] = \"\"\n",
    "people[\"full_name\"] = (\n",
    "    people[NAME_COLS]\n",
    "    .fillna(\"\")\n",
    "    .apply(lambda r: \" \".join(w.strip().lower() for w in r if w), axis=1)\n",
    ")\n",
    "people[\"birthyear\"] = pd.to_numeric(people[\"birthyear\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "people[\"heimild\"]   = pd.to_numeric(people[\"heimild\"],   errors=\"coerce\").fillna(0).astype(int)\n",
    "people[\"sex_male\"]  = people[\"sex\"].apply(lambda x: 1 if isinstance(x, str) and x.lower()==\"karl\" else 0).astype(int)\n",
    "people[\"has_partner\"]= people[\"partner\"].notna().astype(int)\n",
    "people[\"has_father\"] = people[\"father\"].notna().astype(int)\n",
    "people[\"has_mother\"] = people[\"mother\"].notna().astype(int)\n",
    "\n",
    "# 3) Load and join manntol IDs\n",
    "print(\"Loading manntol_einstaklingar_new.csv and merging ID columns…\")\n",
    "mann = pd.read_csv(\n",
    "    DATA_DIR / \"manntol_einstaklingar_new.csv\",\n",
    "    dtype=str,\n",
    "    usecols=[\"id\",\"bi_sokn\",\"bi_hreppur\",\"bi_sysla\",\"thsk_maki\",\"thsk_fadir\",\"thsk_modir\"]\n",
    ").rename(columns={\n",
    "    \"bi_sokn\":    \"parish_id\",\n",
    "    \"bi_hreppur\": \"district_id\",\n",
    "    \"bi_sysla\":   \"county_id\",\n",
    "    \"thsk_maki\":  \"partner_mann\",\n",
    "    \"thsk_fadir\": \"father_mann\",\n",
    "    \"thsk_modir\": \"mother_mann\",\n",
    "})\n",
    "mann[\"id\"] = mann[\"id\"].astype(people.index.dtype)\n",
    "mann = mann.set_index(\"id\")\n",
    "people = people.join(\n",
    "    mann[[\"parish_id\",\"district_id\",\"county_id\",\"partner_mann\",\"father_mann\",\"mother_mann\"]],\n",
    "    how=\"left\"Longitudinal Identity Resolution Task\n",
    ")\n",
    "people[\"partner\"] = people[\"partner\"].fillna(people[\"partner_mann\"])\n",
    "people[\"father\"]  = people[\"father\"].fillna(people[\"father_mann\"])\n",
    "people[\"mother\"]  = people[\"mother\"].fillna(people[\"mother_mann\"])\n",
    "people = people.drop(columns=[\"partner_mann\",\"father_mann\",\"mother_mann\"])\n",
    "\n",
    "# 4) Merge geography\n",
    "print(\"Merging geography data via manntol IDs…\")\n",
    "for fname, idcol, merge_on, newcol in [\n",
    "    (\"parishes.csv\",  \"id\", \"parish_id\",   \"parish_full\"),\n",
    "    (\"districts.csv\", \"id\", \"district_id\", \"district_name\"),\n",
    "    (\"counties.csv\",  \"id\", \"county_id\",   \"county_name\"),\n",
    "]:\n",
    "    try:\n",
    "        geo = pd.read_csv(DATA_DIR / fname, low_memory=False)\n",
    "        geo.columns = geo.columns.str.lower().str.strip()\n",
    "        geo[idcol] = geo[idcol].astype(str)\n",
    "        col_ren = \"full_name\" if newcol==\"parish_full\" else \"name\"\n",
    "        geo = geo.rename(columns={idcol: idcol, col_ren: newcol})\n",
    "        if merge_on not in people.columns:\n",
    "            print(f\"Warning: '{merge_on}' missing; skipping {fname}\")\n",
    "            continue\n",
    "        people = people.merge(\n",
    "            geo[[idcol,newcol]],\n",
    "            left_on=merge_on, right_on=idcol,\n",
    "            how=\"left\", suffixes=(\"\", \"_drop\")\n",
    "        ).drop(columns=[c for c in people.columns if c.endswith(\"_drop\") or c==idcol])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: {fname} not found; skipping\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: error merging {fname}: {e}\")\n",
    "\n",
    "# 5) Impute static attributes\n",
    "print(\"Imputing static attributes…\")\n",
    "if \"person\" in people.columns:\n",
    "    for col in [\"full_name\",\"birthyear\",\"sex_male\"]:\n",
    "        if col in people.columns:\n",
    "            people[col] = people.groupby(\"person\")[col].transform(lambda x: x.ffill().bfill())\n",
    "else:\n",
    "    print(\"Warning: 'person' column not found. Skipping imputation.\")\n",
    "people[\"full_name\"] = people[\"full_name\"].fillna(\"unknown\")\n",
    "people[\"birthyear\"] = people[\"birthyear\"].fillna(0).astype(int)\n",
    "people[\"sex_male\"] = people[\"sex_male\"].fillna(0).astype(int)\n",
    "\n",
    "# 6) **Include ALL rows** for ML features and graph\n",
    "print(\"Including ALL rows for ML features and graph…\")\n",
    "people_ml = people.copy()\n",
    "print(f\"→ {len(people_ml)} total rows\")\n",
    "\n",
    "# Export full row_labels.csv\n",
    "pd.DataFrame({\n",
    "    \"row_id\": people_ml.index,\n",
    "    \"person\": people_ml[\"person\"].astype(str)\n",
    "}).to_csv(ART_DIR / \"row_labels.csv\", index=False)\n",
    "\n",
    "# Export just the linked subset\n",
    "people_ml.loc[people_ml[\"person\"].notna(), [\"person\"]] \\\n",
    "         .to_csv(ART_DIR / \"rows_with_person.csv\", index_label=\"row_id\")\n",
    "\n",
    "# 7) Define feature sets\n",
    "print(\"Defining feature sets…\")\n",
    "NUM_COLS = [\"birthyear\",\"heimild\",\"sex_male\",\"has_partner\",\"has_father\",\"has_mother\"]\n",
    "CAT_LOW  = [\"status\",\"marriagestatus\",\"district_name\",\"county_name\"]\n",
    "CAT_HIGH = [\"parish_full\"]\n",
    "for col in NUM_COLS+CAT_LOW+CAT_HIGH:\n",
    "    if col not in people_ml.columns:\n",
    "        people_ml[col] = 0 if col in NUM_COLS else \"\"\n",
    "\n",
    "# 8) Numeric matrix\n",
    "print(\"Creating numeric features…\")\n",
    "X_num = people_ml[NUM_COLS].values.astype(np.float32)\n",
    "\n",
    "# 9) One-hot low-cardinality\n",
    "print(\"One-hot encoding low-cardinality…\")\n",
    "ohe   = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
    "X_low = ohe.fit_transform(people_ml[CAT_LOW].fillna(\"\").astype(str))\n",
    "low_cols = ohe.get_feature_names_out(CAT_LOW)\n",
    "\n",
    "# 10) Ordinal high-cardinality\n",
    "print(\"Ordinal encoding high-cardinality…\")\n",
    "ord_enc = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "X_high = ord_enc.fit_transform(people_ml[CAT_HIGH].fillna(\"\").astype(str)).astype(np.float32)\n",
    "\n",
    "# 11) Save sparse features\n",
    "print(\"Saving sparse features...\")\n",
    "sparse.save_npz(\n",
    "    ART_DIR / \"iceid_ml_ready.npz\",\n",
    "    sparse.hstack([sparse.csr_matrix(X_num), X_low, sparse.csr_matrix(X_high)], format=\"csr\")\n",
    ")\n",
    "\n",
    "# 12) Create temporal graph\n",
    "print(\"Creating temporal graph…\")\n",
    "row_id_to_idx = {rid:i for i,rid in enumerate(people_ml.index)}\n",
    "edges = []\n",
    "for _,grp in people_ml[people_ml[\"person\"].notna()].groupby(\"person\"):\n",
    "    ids = grp.sort_values(\"heimild\").index\n",
    "    idx = [row_id_to_idx[r] for r in ids]\n",
    "    edges += [[u,v] for u,v in zip(idx, idx[1:])] + [[v,u] for u,v in zip(idx, idx[1:])]\n",
    "edge_index = (torch.tensor(edges, dtype=torch.long).t()\n",
    "              if edges else torch.empty((2,0),dtype=torch.long))\n",
    "graph = Data(edge_index=edge_index)\n",
    "graph.node_id = torch.tensor(people_ml.index.values, dtype=torch.long)\n",
    "# save only the *structure* (edges + node IDs), not x\n",
    "torch.save({\n",
    "    \"edge_index\": graph.edge_index,\n",
    "    \"node_id\":    graph.node_id\n",
    "}, ART_DIR / \"temporal_graph.pt\")\n",
    "print(f\"Graph: {graph.num_nodes} nodes, {graph.num_edges//2} undirected edges.\")\n",
    "print(\"--- Data Preprocessing Finished ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ICE-ID-2.0-K4yMlCOc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
